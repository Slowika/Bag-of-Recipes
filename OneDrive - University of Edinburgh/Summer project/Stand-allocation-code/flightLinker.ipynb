{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Linker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function # because we're running Python 2\n",
    "import os                                       # to make file paths independent of the operating system\n",
    "import numpy as np                              # scientific computing package\n",
    "import pandas as pd                             # data analysis library\n",
    "import time                                     # library to handle time\n",
    "import re                                       # regular expressions\n",
    "import datetime as dt                           # library to handle dates\n",
    "import itertools                                # iteration functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be replaced with user input\n",
    "start_date_str = '08/04/2018'\n",
    "end_date_str   = '08/04/2018'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_range(date1,date2):\n",
    "    ''' Function to iterate over dates'''\n",
    "    \n",
    "    while date1 <= date2:\n",
    "        yield date1\n",
    "        date1 = date1 + dt.timedelta(days=1)\n",
    "    \n",
    "    \n",
    "def make_datetime(row):\n",
    "    ''' Function to combine date, hour and minutes into a datetime field'''\n",
    "    \n",
    "    time = str(int(row['TIME']))\n",
    "    len_ = len(time)\n",
    "    \n",
    "    if len_ < 3 :\n",
    "        hour   = 0\n",
    "        minute = int(time)\n",
    "    else:\n",
    "        hour   = int(time[0:(len_-2)])\n",
    "        minute = int(time[-2:])\n",
    "        \n",
    "    return row['FLIGHT_DATE'] + dt.timedelta(hours=hour) + dt.timedelta(minutes=minute)\n",
    "\n",
    "\n",
    "def select_dates(row):\n",
    "    ''' For a given service (row), select all days between start and end data\n",
    "        that match the days of the week given in the frequency field.\n",
    "        Return a list of all selected dates for each service.'''\n",
    "    \n",
    "    return [date for date in date_range(row['START'], row['END']) if \n",
    "            str(dt.datetime.weekday(date) + 1) in row['FREQ']]\n",
    "\n",
    "def truncate_arr_date(row):\n",
    "    if row['DATETIME_x'] < start_date:\n",
    "        out = start_date\n",
    "    else:\n",
    "        out = row['DATETIME_x']\n",
    "    return out\n",
    "\n",
    "def truncate_dep_date(row):\n",
    "    if row['DATETIME_y'] > end_date + dt.timedelta(days=1):\n",
    "        out = end_date + dt.timedelta(days=1)\n",
    "    else:\n",
    "        out = row['DATETIME_y']           \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6045 services in this file\n",
      "Cleaning the file...\n"
     ]
    }
   ],
   "source": [
    "# Create flight path compatible with all operating systems\n",
    "data_path = os.path.join(os.getcwd(), 'data', '180312_ACL.csv')\n",
    "\n",
    "# Import ACL schedule\n",
    "acl_original = pd.read_csv(data_path, delimiter = ',')\n",
    "\n",
    "print(\"There are %s services in this file\" % (acl_original.shape[0]-1))\n",
    "print(\"Cleaning the file...\")\n",
    "\n",
    "# Delete first row with column names\n",
    "acl_services = acl_original.drop(0).reset_index(drop=True)\n",
    "\n",
    "# Delete useless columns\n",
    "acl_services.drop(['REQ','CLEAR','TERM','WKY','REC','L/N','T/R','LAST'], axis=1, inplace=True)\n",
    "\n",
    "# Convert columns with dates to date format\n",
    "acl_services['START'] = pd.to_datetime(acl_services['START'])\n",
    "acl_services['END']   = pd.to_datetime(acl_services['END'])\n",
    "\n",
    "# Create a list of weekdays of each service\n",
    "acl_services['FREQ'] = [re.compile(r'\\d').findall(flight) for flight in acl_services['FREQ']]\n",
    "\n",
    "# Add column with operator\n",
    "acl_services.insert(1, 'OPERATOR', [service[0:3].replace(' ','') for service in acl_services['SERVICE']])\n",
    "\n",
    "acl_services['SERVICE'] = [x.replace(' ','') for x in acl_services.SERVICE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working out all the flight dates of each service...\n",
      "Repeating each service as many times as dates it flies...\n"
     ]
    }
   ],
   "source": [
    "# Initialise lists\n",
    "flight_dates = []\n",
    "number_dates = []\n",
    "\n",
    "print(\"Working out all the flight dates of each service...\")\n",
    "\n",
    "# Create a list of all the dates that should be considered\n",
    "# (apply + lambda allows to apply a calculation that does not take vectors on the entire column)\n",
    "flight_dates = acl_services.apply(lambda row: select_dates(row), axis=1)\n",
    "\n",
    "# Create a new column with the number of dates for each service\n",
    "acl_services['DATE_COUNT'] = flight_dates.apply(len)\n",
    "\n",
    "print(\"Repeating each service as many times as dates it flies...\")\n",
    "\n",
    "# Create a new dataframe with one row per flight, using the values in the column created above to know\n",
    "# how many times to repeat each flight\n",
    "acl_flights = acl_services.loc[np.repeat(acl_services.index.values, acl_services['DATE_COUNT'])]\n",
    "\n",
    "# Turn off warning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Create a new column containing the flight date\n",
    "acl_flights['FLIGHT_DATE'] = list(itertools.chain(*flight_dates))\n",
    "\n",
    "# Drop columns that we don't need anymore\n",
    "acl_flights.drop(['FREQ','DATE_COUNT','START','END'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning dates and times and adding auxiliary fields...\n"
     ]
    }
   ],
   "source": [
    "# Separate departures from arrivals\n",
    "departures = acl_flights[acl_flights['A/D'] == 'D']\n",
    "arrivals   = acl_flights[acl_flights['A/D'] == 'A']\n",
    "\n",
    "# Keep only flights from one week before the stand plan week to one week after\n",
    "arrivals =   arrivals[  (arrivals['FLIGHT_DATE']   >= start_date - dt.timedelta(days=7)) &\n",
    "                        (arrivals['FLIGHT_DATE']   <= end_date + dt.timedelta(days=7))]\n",
    "\n",
    "departures = departures[(departures['FLIGHT_DATE'] >= start_date - dt.timedelta(days=7)) & \n",
    "                        (departures['FLIGHT_DATE'] <= end_date + dt.timedelta(days=7))]\n",
    "\n",
    "print(\"Cleaning dates and times and adding auxiliary fields...\")\n",
    "\n",
    "# Reset indeces\n",
    "departures.reset_index(inplace=True, drop=True)\n",
    "arrivals.reset_index  (inplace=True, drop=True)\n",
    "\n",
    "# Create a column with date and time combining existing columns\n",
    "arrivals  ['DATETIME'] = arrivals.apply  (lambda row: make_datetime(row), axis=1)\n",
    "departures['DATETIME'] = departures.apply(lambda row: make_datetime(row), axis=1)\n",
    "\n",
    "# Add a unique ID to the departures and arrivals dataframes\n",
    "departures['ID']   = np.core.defchararray.add('D', departures.index.values.astype(dtype=str))\n",
    "\n",
    "# Initialise 'LINK' field for connecting arrivals with departures\n",
    "arrivals  ['LINK'] = ''\n",
    "departures['LINK'] = 0\n",
    "\n",
    "# Sort dataframes by datetime\n",
    "arrivals.sort_values  ('DATETIME', inplace=True)\n",
    "departures.sort_values('DATETIME', inplace=True)\n",
    "\n",
    "# Reset indices\n",
    "arrivals.reset_index  (drop=True, inplace=True)\n",
    "departures.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINKING FLIGHTS: STEP 1:\n",
    "# ------------------------\n",
    "# Find linking flight for all arrivals with turnaround information\n",
    "# Based on the assumption that if an arriving flights contains the flight number of the turnaround,\n",
    "# its departing turnaround also contains the flight number of the arrival\n",
    "\n",
    "for arr_idx, arr in arrivals.iterrows():\n",
    "    # If the turnaround field is not empty, if this arriving flight has not been assigned to a departure yet and\n",
    "    # if the flight arrives inside the stand plan window\n",
    "    if (arr['TROUND'] != ' '*8) & (arr['LINK'] != 1):\n",
    "        \n",
    "        # Subset of departures that depart after the time of the arrival and \n",
    "        # whose flight number matches the turnaround flight for this arrival\n",
    "        subset = departures[(departures['SERVICE'] == arr['TROUND']) &\n",
    "                            (departures['TROUND']  == arr['SERVICE'])&\n",
    "                            (departures['DATETIME'] > arr['DATETIME'])]\n",
    "        \n",
    "        if len(subset['DATETIME']) != 0:\n",
    "            # Get the index of the departing flight with the earliest time\n",
    "            dep_idx = subset['DATETIME'].idxmin()\n",
    "            arrivals.loc  [arr_idx,'LINK'] = departures.iloc[dep_idx]['ID']\n",
    "            departures.loc[dep_idx,'LINK'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINKING FLIGHTS: STEP 2:\n",
    "# ------------------------\n",
    "# Find linking flight for all arrivals without turnaround information\n",
    "\n",
    "for arr_idx, arr in arrivals.iterrows():\n",
    "    \n",
    "    # If the turnaround field is not empty and if the flight departs inside the stand plan window\n",
    "    if arr['LINK'] == '':\n",
    "        # Subset of arrivals candidates\n",
    "        subset = departures[(departures['AC']       == arr['AC'])    &    # must have the same aircraft\n",
    "                            (departures['OPERATOR'] == arr['OPERATOR']) & # operated by the same airline                           \n",
    "                            (departures['DATETIME'] >= arr['DATETIME'] + dt.timedelta(minutes=20)) &\n",
    "                            (departures['LINK']     == 0)]               # cannot be linked to another dep\n",
    "        \n",
    "        #if len(subset['DATETIME']) == 0: pdb.set_trace()\n",
    "        \n",
    "        if len(subset['DATETIME']) != 0:\n",
    "            # Get the index of the departing flight with the earliest time\n",
    "            dep_idx = subset['DATETIME'].idxmin() \n",
    "            arrivals.loc  [arr_idx,'LINK'] = departures.iloc[dep_idx]['ID']\n",
    "            departures.loc[dep_idx,'LINK'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrivals.drop  (['TIME'], axis=1, inplace=True)\n",
    "departures.drop(['TIME'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inner join of departures and arrivals\n",
    "linked = arrivals.merge(departures, left_on='LINK', right_on='ID', how='inner')\n",
    "\n",
    "# Add field with turnaround time\n",
    "linked['TURN_MINUTES'] = [delta.seconds//60 for delta in (linked.DATETIME_y - linked.DATETIME_x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234 flights were linked\n"
     ]
    }
   ],
   "source": [
    "# Sparse dataset for optimization\n",
    "linked_clean = linked.copy()\n",
    "\n",
    "# Filter flights in stand plan week\n",
    "linked_clean = linked_clean[(linked_clean['FLIGHT_DATE_x'] <= end_date) & \\\n",
    "                            (linked_clean['FLIGHT_DATE_y'] >= start_date)]\n",
    "\n",
    "linked_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Eliminate irrelevant fields\n",
    "linked_clean.drop(['LINK_x','A/D_x','A/D_y','AC_y','TROUND_y','ID','LINK_y',\\\n",
    "                   'OPERATOR_y', 'FLIGHT_DATE_x','FLIGHT_DATE_y'], axis=1, inplace=True)\n",
    "\n",
    "print(\"%s flights were linked\" % (linked_clean.shape[0]))\n",
    "\n",
    "# If the flight datetimes are outside the allocation window, truncate them\n",
    "linked_clean.DATETIME_x = linked_clean.apply(lambda row: truncate_arr_date(row), axis=1)\n",
    "linked_clean.DATETIME_y = linked_clean.apply(lambda row: truncate_dep_date(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform outer join for analysis of flights that were not linked\n",
    "linked_outer = arrivals.merge(departures, left_on='LINK', right_on='ID', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export files\n",
    "data_path = os.path.join(os.getcwd(), 'output', 'arrivals.csv')\n",
    "arrivals.    to_csv(data_path, index=False)\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), 'output', 'departures.csv')\n",
    "departures.  to_csv(data_path, index=False)\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), 'output', 'turnarounds.csv')\n",
    "linked_clean.to_csv(data_path, index=False)\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), 'output', 'turns_outer.csv')\n",
    "linked_outer.to_csv(data_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
