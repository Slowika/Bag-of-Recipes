{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight Linker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function # because we're running Python 2\n",
    "import os                                       # to make file paths independent of the operating system\n",
    "import numpy as np                              # scientific computing package\n",
    "import pandas as pd                             # data analysis library\n",
    "import time                                     # library to handle time\n",
    "import re                                       # regular expressions\n",
    "import datetime as dt                           # library to handle dates\n",
    "import itertools                                # iteration functions\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_range(date1,date2):\n",
    "    ''' Function to iterate over dates'''\n",
    "    \n",
    "    while date1 <= date2:\n",
    "        yield date1\n",
    "        date1 = date1 + dt.timedelta(days=1)\n",
    "    \n",
    "    \n",
    "def make_datetime(row):\n",
    "    ''' Function to combine date, hour and minutes into a datetime field'''\n",
    "    \n",
    "    time = str(int(row['TIME']))\n",
    "    len_ = len(time)\n",
    "    \n",
    "    if len_ < 3 :\n",
    "        hour   = 0\n",
    "        minute = int(time)\n",
    "    else:\n",
    "        hour   = int(time[0:(len_-2)])\n",
    "        minute = int(time[-2:])\n",
    "        \n",
    "    return row['FLIGHT_DATE'] + dt.timedelta(hours=hour) + dt.timedelta(minutes=minute)\n",
    "\n",
    "\n",
    "def select_dates(row):\n",
    "    ''' For a given service (row), select all days between start and end data\n",
    "        that match the days of the week given in the frequency field.\n",
    "        Return a list of all selected dates for each service.'''\n",
    "    \n",
    "    return [date for date in date_range(row['START'], row['END']) if \n",
    "            str(dt.datetime.weekday(date) + 1) in row['FREQ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6045 services in this file\n",
      "Cleaning the file...\n"
     ]
    }
   ],
   "source": [
    "# To be replaced with user input\n",
    "start_date_str = '08/04/2018'\n",
    "end_date_str   = '08/04/2018'\n",
    "\n",
    "# Convert strings to dates\n",
    "start_date = pd.to_datetime(start_date_str, format='%d/%m/%Y')\n",
    "end_date   = pd.to_datetime(end_date_str, format='%d/%m/%Y')\n",
    "\n",
    "# Create flight path compatible with all operating systems\n",
    "data_path = os.path.join(os.getcwd(), 'data', '180312_ACL.csv')\n",
    "\n",
    "# Import ACL schedule\n",
    "acl_original = pd.read_csv(data_path, delimiter = ',')\n",
    "\n",
    "print(\"There are %s services in this file\" % (acl_original.shape[0]-1))\n",
    "print(\"Cleaning the file...\")\n",
    "\n",
    "# Delete first row with column names\n",
    "acl_services = acl_original.drop(0).reset_index(drop=True)\n",
    "\n",
    "# Delete useless columns\n",
    "acl_services.drop(['REQ','CLEAR','TERM','WKY','REC','L/N','T/R','LAST'], axis=1, inplace=True)\n",
    "\n",
    "# Convert columns with dates to date format\n",
    "acl_services['START'] = pd.to_datetime(acl_services['START'])\n",
    "acl_services['END']   = pd.to_datetime(acl_services['END'])\n",
    "\n",
    "# Create a list of weekdays of each service\n",
    "acl_services['FREQ'] = [re.compile(r'\\d').findall(flight) for flight in acl_services['FREQ']]\n",
    "\n",
    "# Add column with operator\n",
    "acl_services.insert(1, 'OPERATOR', [service[0:3] for service in acl_services['SERVICE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working out all the flight dates of each service...\n"
     ]
    }
   ],
   "source": [
    "# Initialise lists\n",
    "flight_dates = []\n",
    "number_dates = []\n",
    "\n",
    "print(\"Working out all the flight dates of each service...\")\n",
    "\n",
    "# Create a list of all the dates that should be considered\n",
    "flight_dates = acl_services.apply(lambda row: select_dates(row), axis=1)\n",
    "\n",
    "# Create a new column with the number of dates for each service\n",
    "acl_services['DATE_COUNT'] = flight_dates.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeating each service as many times as dates it flies...\n"
     ]
    }
   ],
   "source": [
    "print(\"Repeating each service as many times as dates it flies...\")\n",
    "\n",
    "# Create a new dataframe with one row per flight, using the values in the column created above to know\n",
    "# how many times to repeat each flight\n",
    "acl_flights = acl_services.loc[np.repeat(acl_services.index.values, acl_services['DATE_COUNT'])]\n",
    "\n",
    "# Turn off warning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Create a new column containing the flight date\n",
    "acl_flights['FLIGHT_DATE'] = list(itertools.chain(*flight_dates))\n",
    "\n",
    "# Drop columns that we don't need anymore\n",
    "acl_flights.drop(['FREQ','DATE_COUNT','START','END'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate departures from arrivals\n",
    "departures = acl_flights[acl_flights['A/D'] == 'D']\n",
    "arrivals   = acl_flights[acl_flights['A/D'] == 'A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate those flights for which we are 100% sure they are not relevant for the stand plan week\n",
    "arrivals =   arrivals[  (arrivals['FLIGHT_DATE']   >= start_date - dt.timedelta(days=15)) &\n",
    "                        (arrivals['FLIGHT_DATE']   <= end_date)]\n",
    "\n",
    "departures = departures[(departures['FLIGHT_DATE'] >= start_date) & \n",
    "                        (departures['FLIGHT_DATE'] <= end_date + dt.timedelta(days=15))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning dates and times and adding auxiliary fields...\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning dates and times and adding auxiliary fields...\")\n",
    "# Reset indeces\n",
    "departures.reset_index(inplace=True, drop=True)\n",
    "arrivals.reset_index  (inplace=True, drop=True)\n",
    "\n",
    "# Create a column with date and time combining existing columns\n",
    "arrivals  ['DATETIME'] = arrivals.apply  (lambda row: make_datetime(row), axis=1)\n",
    "departures['DATETIME'] = departures.apply(lambda row: make_datetime(row), axis=1)\n",
    "\n",
    "# Add a unique ID to the departures and arrivals dataframes\n",
    "departures['ID']   = np.core.defchararray.add('D', departures.index.values.astype(dtype=str))\n",
    "\n",
    "# Initialise 'LINK' field for connecting arrivals with departures\n",
    "arrivals  ['LINK'] = ''\n",
    "departures['LINK'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframes by datetime\n",
    "arrivals.sort_values  ('DATETIME', inplace=True)\n",
    "departures.sort_values('DATETIME', inplace=True)\n",
    "\n",
    "arrivals.reset_index  (drop=True, inplace=True)\n",
    "departures.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINKING FLIGHTS: STEP 1:\n",
    "# ------------------------\n",
    "\n",
    "# Find linking flight for departures IN stand plan week\n",
    "# only for flights with turnaround information\n",
    "\n",
    "# for dep_idx, dep in departures.iterrows():\n",
    "#     # If the turnaround field is not empty and if the flight departs inside the stand plan window\n",
    "#     if (dep['TROUND'] != ' '*8) & (dep['FLIGHT_DATE'] <= end_date):\n",
    "        \n",
    "#         # Subset of arrivals that arrive before the time of departure and whose flight number\n",
    "#         # matches the turnaround flight for this arrival\n",
    "#         subset = arrivals[(arrivals['SERVICE'] == dep['TROUND']) &\n",
    "#                           (arrivals['DATETIME'] < dep['DATETIME'])]\n",
    "        \n",
    "#         # Get the index of the arriving flight with the latest time\n",
    "#         arr_idx = subset['DATETIME'].idxmax()\n",
    "#         departures.loc[dep_idx,'LINK'] = 1\n",
    "#         arrivals.loc  [arr_idx,'LINK'] = departures.iloc[dep_idx]['ID']\n",
    "\n",
    "# Find linking flight for departures IN stand plan week\n",
    "# only for flights with turnaround information\n",
    "\n",
    "for arr_idx, arr in arrivals.iterrows():\n",
    "    # If the turnaround field is not empty, if this arriving flight has not been assigned to a departure yet and\n",
    "    # if the flight arrives inside the stand plan window\n",
    "    if (arr['TROUND'] != ' '*8) & (arr['LINK'] != 1): #& (arr['FLIGHT_DATE'] >= start_date):\n",
    "        \n",
    "        # Subset of departures that depart after the time of the arrival and \n",
    "        # whose flight number matches the turnaround flight for this arrival\n",
    "        subset = departures[(departures['SERVICE'] == arr['TROUND']) &\n",
    "                            (departures['DATETIME'] > arr['DATETIME'])]\n",
    "        \n",
    "        if len(subset['DATETIME']) != 0:\n",
    "            # Get the index of the departing flight with the earliest time\n",
    "            dep_idx = subset['DATETIME'].idxmin()\n",
    "\n",
    "            arrivals.loc  [arr_idx,'LINK'] = departures.iloc[dep_idx]['ID']\n",
    "            departures.loc[dep_idx,'LINK'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINKING FLIGHTS: STEP 2:\n",
    "# ------------------------\n",
    "\n",
    "# Find linking flight for departures IN stand plan week\n",
    "# without turnaround information: first in - first out\n",
    "\n",
    "# for dep_idx, dep in departures.iterrows():\n",
    "    \n",
    "#     # If the turnaround field is not empty and if the flight departs inside the stand plan window\n",
    "#     if (dep['LINK'] == 0) & (dep['FLIGHT_DATE'] <= end_date):\n",
    "#         # Subset of arrivals candidates\n",
    "#         subset = arrivals[(arrivals['AC']       == dep['AC'])    &    # must have the same aircraft\n",
    "#                           (arrivals['OPERATOR'] == dep['OPERATOR']) & # operated by the same airline                           \n",
    "#                           (arrivals['DATETIME'] <= dep['DATETIME'] - dt.timedelta(minutes=20)) &\n",
    "#                           (arrivals['LINK']     == '')]               # cannot be linked to another dep\n",
    "        \n",
    "#         #if dep['OPERATOR'] == 'BA ': pdb.set_trace()\n",
    "        \n",
    "#         # Get the index of the arriving flight with the latest time\n",
    "#         arr_idx = subset['DATETIME'].idxmax()\n",
    "#         departures.loc[dep_idx,'LINK'] = 1\n",
    "#         arrivals.loc  [arr_idx,'LINK'] = departures.iloc[dep_idx]['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arr_idx, arr in arrivals.iterrows():\n",
    "    \n",
    "    # If the turnaround field is not empty and if the flight departs inside the stand plan window\n",
    "    if (arr['LINK'] == ''): #& (arr['FLIGHT_DATE'] >= start_date):\n",
    "        # Subset of arrivals candidates\n",
    "        subset = departures[(departures['AC']       == arr['AC'])    &    # must have the same aircraft\n",
    "                            (departures['OPERATOR'] == arr['OPERATOR']) & # operated by the same airline                           \n",
    "                            (departures['DATETIME'] >= arr['DATETIME'] + dt.timedelta(minutes=20)) &\n",
    "                            (departures['LINK']     == 0)]               # cannot be linked to another dep\n",
    "        \n",
    "        #if len(subset['DATETIME']) == 0: pdb.set_trace()\n",
    "        #if dep['OPERATOR'] == 'BA ': pdb.set_trace()\n",
    "        \n",
    "        # Get the index of the departing flight with the earliest time\n",
    "        dep_idx = subset['DATETIME'].idxmin() \n",
    "        arrivals.loc  [arr_idx,'LINK'] = departures.iloc[dep_idx]['ID']\n",
    "        departures.loc[dep_idx,'LINK'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "departures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrivals.drop  (['TIME','FLIGHT_DATE'], axis=1, inplace=True)\n",
    "departures.drop(['TIME','FLIGHT_DATE'], axis=1, inplace=True)\n",
    "\n",
    "# Perform inner join of departures and arrivals\n",
    "linked = arrivals.merge(departures, left_on='LINK', right_on='ID', how='inner')\n",
    "linked.drop(['LINK_x'], axis=1, inplace=True)\n",
    "linked['TURN_MINUTES'] = [delta.seconds//60 for delta in (linked.DATETIME_y - linked.DATETIME_x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrivals.to_csv('out/arrivals.csv')\n",
    "departures.to_csv('out/departures.csv')\n",
    "linked.to_csv('out/inner_turns_for_checks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linked_clean = linked.copy()\n",
    "linked_clean.drop(['A/D_x','A/D_y','AC_y','TROUND_y','ID','LINK_y','OPERATOR_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linked_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
