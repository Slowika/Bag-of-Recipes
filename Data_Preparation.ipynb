{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting potential ingredients given partial recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sklearn\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets to notebook from json files, prepare data to convert to bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*  Recipe dictionary: \n",
      " {'id': 10259, 'cuisine': 'greek', 'ingredients': ['romaine lettuce', 'black olives', 'grape tomatoes', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo beans', 'feta cheese crumbles']}\n",
      "\n",
      "*  Input for CountVectorizer: \n",
      " romainelettuce blackolives grapetomatoes garlic pepper purpleonion seasoning garbanzobeans fetacheesecrumbles\n"
     ]
    }
   ],
   "source": [
    "# Initialise empty lists\n",
    "train_ingr    = [] # Lists to save set of ingredients for each recipe...\n",
    "\n",
    "train_id      = [] # Lists to store recipe id for recipes in both\n",
    "\n",
    "train_cuisine = [] # Training data contains additional information with cuisine\n",
    "\n",
    "# Load json files as lists of dictionaries for each recipe\n",
    "with open('data/train.json') as json_file:  # Load train data\n",
    "    dict_train = json.load(json_file)\n",
    "\n",
    "    \n",
    "# Process the data to make it suitable for CountVectorizer    \n",
    "for train_recipe in dict_train: # iterate over dictionaries of recipes\n",
    "    \n",
    "    # For each dictionary with a recipe, replace spaces between words from the same ingredient \n",
    "    # with an underscore '_', then join all the ingredients in each recipe in a \n",
    "    # long string where ingredients are separated by spaces ' '.\n",
    "    concat_ingr_tr = ' '.join([word.replace(\" \", \"\") for word in train_recipe['ingredients']])\n",
    "    \n",
    "    # Append the result from previous step to the list of recipes with ingredients\n",
    "    train_ingr.append(concat_ingr_tr)\n",
    "    \n",
    "    # Append the recipe id to list of recipe id's\n",
    "    train_id.append(train_recipe['id'])\n",
    "    \n",
    "    # Append the cuisine to list of recipe id's\n",
    "    train_cuisine.append(train_recipe['cuisine'])\n",
    "        \n",
    "    \n",
    "\n",
    "print(\"\\n*  Recipe dictionary: \\n\",dict_train[0])\n",
    "    \n",
    "# Display first three elements of test_ingr\n",
    "print(\"\\n*  Input for CountVectorizer: \\n\",train_ingr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to 'bag-of-ingredients' format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Transform list of ingredients to bag-of-ingredients format, for train and \n",
    "# test sets, and store in a pandas data frame\n",
    "X_train = pd.DataFrame(vectorizer.fit_transform(train_ingr).todense())\n",
    "\n",
    "# Add column names, using keys from vectorizer dictionary\n",
    "X_train.columns = sorted(vectorizer.vocabulary_, key=vectorizer.vocabulary_.get)\n",
    "\n",
    "# Add recipe id\n",
    "X_train.index = train_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the size of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:\n",
      " *  39774 recipes\n",
      " *  6782 ingredients\n",
      "\n",
      "Test data size:\n",
      " *  9944 recipes\n",
      " *  6782 ingredients\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data size:\\n *  {} recipes\\n *  {} ingredients\".format(X_train.shape[0], X_train.shape[1]))\n",
    "print(\"\\nTest data size:\\n *  {} recipes\\n *  {} ingredients\".format(X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data size:\n",
      " *  49718 recipes\n"
     ]
    }
   ],
   "source": [
    "print(\"Total data size:\\n *  {} recipes\".format(X_train.shape[0] + X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* ingredients removed for being numeric or appearing <= 3 times 0\n",
      "\n",
      "* sample of infrequent ingredients\n",
      " aburaage                4\n",
      "accentseasoning         6\n",
      "achiote                 8\n",
      "achiotepaste           11\n",
      "achiotepowder           4\n",
      "ackee                   9\n",
      "acornsquash            18\n",
      "actingbakingpowder     21\n",
      "activedryyeast        377\n",
      "addedblackbeans        18\n",
      "addeddicedtomatoes     18\n",
      "adobo                  15\n",
      "adobosauce             94\n",
      "adoboseasoning         10\n",
      "adzukibeans             5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each ingredient\n",
    "ingr_count = X_train.sum(axis=0)\n",
    "\n",
    "def hasNumbers(inputString):\n",
    "     return any(char.isdigit() for char in inputString)\n",
    "    \n",
    "num_elem = [hasNumbers(ingr) for ingr in X_train.columns] # ingredients that contain a number\n",
    "leq_three = list(ingr_count <= 3)                         # ingredients that appear three times or less\n",
    "\n",
    "removed_idx = [a or b for a, b in zip(num_elem, leq_three)] # ingredients that meet both criteria\n",
    "\n",
    "\n",
    "# Sum number of ingredients that appear 3 times or less\n",
    "print('* ingredients removed for being numeric or appearing <= 3 times',sum(removed_idx))\n",
    "\n",
    "# Display examples of infrequent ingredients\n",
    "print('\\n* sample of infrequent ingredients\\n',ingr_count[0:15])\n",
    "\n",
    "X_train.drop(X_train.columns[removed_idx], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hasNumbers(inputString):\n",
    "     return any(char.isdigit() for char in inputString)\n",
    "    \n",
    "indx = [hasNumbers(ingr) for ingr in X_train.columns]\n",
    "X_train.columns[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipes with 2 ingredients or less: 255\n"
     ]
    }
   ],
   "source": [
    "# Count ingredients per recipe\n",
    "recipe_count = X_train.sum(axis=1)\n",
    "print('Recipes with 2 ingredients or less:',sum(recipe_count <= 2))\n",
    "\n",
    "# Remove recipes with 2 ingredients or less\n",
    "X_train = X_train.loc[recipe_count > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:\n",
      " *  39519 recipes\n",
      " *  3717 ingredients\n",
      "\n",
      "Test data size:\n",
      " *  9944 recipes\n",
      " *  6782 ingredients\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data size:\\n *  {} recipes\\n *  {} ingredients\".format(X_train.shape[0], X_train.shape[1]))\n",
    "print(\"\\nTest data size:\\n *  {} recipes\\n *  {} ingredients\".format(X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('train_dataset.csv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
