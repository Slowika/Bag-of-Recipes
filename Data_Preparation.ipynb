{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting potential ingredients given partial recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sklearn\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import string\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data to bag-of-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load datasets to notebook from json files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " def invalidChar(inputString):\n",
    "        # Function to check if a character in a string is a number or a special character\n",
    "        special_char = string.punctuation\n",
    "        out = any(char.isdigit() or char in special_char for char in inputString)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare data to convert to bag of words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load json files as lists of dictionaries for each recipe\n",
    "with open('data/train.json') as json_file:  # Load train data\n",
    "    dict_train = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*  Recipe dictionary: \n",
      " {'id': 10259, 'cuisine': 'greek', 'ingredients': ['romaine lettuce', 'black olives', 'grape tomatoes', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo beans', 'feta cheese crumbles']}\n",
      "\n",
      "*  Input for CountVectorizer: \n",
      " romaine_lettuce black_olives grape_tomatoes garlic pepper purple_onion seasoning garbanzo_beans feta_cheese_crumbles\n"
     ]
    }
   ],
   "source": [
    "# Initialise empty lists\n",
    "train_ingr    = [] # Lists to save set of ingredients for each recipe...\n",
    "train_id      = [] # Lists to store recipe id for recipes in both\n",
    "train_cuisine = [] # Training data contains additional information with cuisine\n",
    "\n",
    "list_of_lists = []\n",
    "\n",
    "# Process the data to make it suitable for CountVectorizer    \n",
    "for train_recipe in dict_train: # iterate over dictionaries of recipes\n",
    "    \n",
    "    # Clean ingredient names\n",
    "    thisIngr = []\n",
    "    for word in train_recipe['ingredients']:\n",
    "        \n",
    "        # Remove and upper case to lower case\n",
    "        # Remove leading white space\n",
    "        word = word.lower().lstrip()\n",
    "        \n",
    "        # Remove numbers and special characters from word\n",
    "        for char in word:\n",
    "            if not(char.islower() or char == ' '): word = word.replace(char,\"\")\n",
    "        \n",
    "        # Remove long spaces, oz, lb\n",
    "        word     = word.replace(\"oz \",\"\")\n",
    "        word     = word.replace(\"lb \",\"\")\n",
    "        word     = word.replace(\"  \",\"\")\n",
    "        \n",
    "        # Replace all spaces with \"_\" to keep separate words\n",
    "        word     = word.replace(\" \",\"_\")\n",
    "        \n",
    "        # List of cleaned ingredients for this recipe\n",
    "        thisIngr.append(word)\n",
    "    \n",
    "    # Create a list of lists of ingredients for each recipe (MAYBE NOT REQUIRED LATER)\n",
    "    list_of_lists.append(thisIngr)\n",
    "    \n",
    "    # For each dictionary with a recipe, replace spaces between words from the same ingredient \n",
    "    # with an underscore '_', then join all the ingredients in each recipe in a \n",
    "    # long string where ingredients are separated by spaces ' '.\n",
    "    concat_ingr_tr = ' '.join([word for word in thisIngr])\n",
    "    \n",
    "    # Append the result from previous step to the list of recipes with ingredients\n",
    "    train_ingr.append(concat_ingr_tr)\n",
    "    \n",
    "    # Append the recipe id to list of recipe id's\n",
    "    train_id.append(train_recipe['id'])\n",
    "    \n",
    "    # Append the cuisine to list of recipe id's\n",
    "    train_cuisine.append(train_recipe['cuisine'])\n",
    "\n",
    "# Save cuisine to dictionary of recipe ids \n",
    "cuisine_dict = dict(zip(train_id, train_cuisine))   \n",
    "\n",
    "# Display first element of ingredient objects\n",
    "print(\"\\n*  Recipe dictionary: \\n\", dict_train[0])\n",
    "print(\"\\n*  Input for CountVectorizer: \\n\", train_ingr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert to 'bag-of-ingredients' format.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise CountVectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Transform list of ingredients to bag-of-ingredients format, for train and \n",
    "# test sets, and store in a pandas data frame\n",
    "X_train = pd.DataFrame(vectorizer.fit_transform(train_ingr).todense())\n",
    "\n",
    "# Add column names, using keys from vectorizer dictionary\n",
    "X_train.columns = sorted(vectorizer.vocabulary_, key=vectorizer.vocabulary_.get)\n",
    "\n",
    "# Add recipe id\n",
    "X_train.index = train_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up strange recipes & ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove underscore before ingredient\n",
    "column_names = vectorizer.get_feature_names()\n",
    "\n",
    "for name_idx, name in enumerate(column_names):\n",
    "    # There could be more than one space!\n",
    "    if name[0] == '_':\n",
    "        X_train.drop(columns = name, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the size of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:\n",
      " *  39774 recipes\n",
      " *  6669 ingredients\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data size:\\n *  {} recipes\\n *  {} ingredients\".format(X_train.shape[0], X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove too rare/too common/nonsense ingredients\n",
    "\n",
    "Perform a fist filter to reduce computational cost of a more sophisticated approach performed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* ingredients removed for being numeric or appearing <= 3 times 3003\n",
      "* ingredients removed for being too short 10\n",
      "* New number of ingredients 3656\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the dataframe for cleaning\n",
    "X_train_cl = X_train.copy(deep=True)\n",
    "\n",
    "# Count occurrences of each ingredient\n",
    "ingr_count = X_train_cl.sum(axis=0)\n",
    "\n",
    " # Ingredients that appear three times or less\n",
    "not_many_ingr = list(ingr_count <= 3)                        \n",
    "\n",
    "# Sum number of ingredients that appear 3 times or less.\n",
    "print('* ingredients removed for being numeric or appearing <= 3 times',sum(not_many_ingr))\n",
    "\n",
    "# Drop infrequent ingredients\n",
    "X_train_cl.drop(X_train_cl.columns[not_many_ingr], axis = 1, inplace = True)\n",
    "\n",
    "# Get index of ingredients of length less than 4 (with some exceptions)\n",
    "accepted_short = [elem not in ['cod', 'pig','gin','ham','hen','ice','jam','oil','pig','rib','soy']\n",
    "                  for elem in X_train_cl.columns]\n",
    "short_ingr = np.array([len(elem) for elem in X_train_cl.columns]) <= 3\n",
    "rm_short_name = [a and b for a, b in zip(accepted_short, short_ingr)]\n",
    "\n",
    "# Drop ingredients of length less than 4 (with some exceptions)\n",
    "X_train_cl.drop(X_train_cl.columns[rm_short_name], axis = 1, inplace = True)\n",
    "\n",
    "# Sum number of ingredients of length less than 3.\n",
    "print('* ingredients removed for being too short',sum(rm_short_name))\n",
    "\n",
    "# New number of ingredients\n",
    "print('* New number of ingredients',len(X_train_cl.columns))\n",
    "\n",
    "# Recount occurrence of ingredients.\n",
    "ingr_count = X_train_cl.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'egar'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def longest_common_substring(s1, s2, thresh=3):\n",
    "    \n",
    "    # Function to find the longest common substring between \n",
    "    # two strings and which is longer than a threshold\n",
    "    m = [[0] * (1 + len(s2)) for i in range(1 + len(s1))]\n",
    "    longest, x_longest = 0, 0\n",
    "    for x in range(1, 1 + len(s1)):\n",
    "        for y in range(1, 1 + len(s2)):\n",
    "            \n",
    "            # I don't want words starting with \"_\"\n",
    "            if s1[x - 1] == s2[y - 1] and s1[x - 1] != \"_\": \n",
    "                m[x][y] = m[x - 1][y - 1] + 1\n",
    "                \n",
    "                # I don't want words with \"_\" in between;\n",
    "                # single words or parts of a word only\n",
    "                if m[x][y] > longest and \"_\" not in s1[x - m[x][y]: x]:\n",
    "                    longest = m[x][y]\n",
    "                    x_longest = x\n",
    "            else:\n",
    "                m[x][y] = 0\n",
    "    out = s1[x_longest - longest: x_longest]\n",
    "    \n",
    "    # Clean underscore after the word\n",
    "    if out != \"\" and out[-1] == \"_\": out = out[:-1]\n",
    "        \n",
    "    if len(out) > thresh:\n",
    "        return out\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def uniqueString(string_list):\n",
    "    # Function to clean a list of strings of strings that are contained in other strings\n",
    "    string_list.sort(key=lambda s: len(s), reverse=True)\n",
    "    out = []\n",
    "    for s in string_list:\n",
    "        if not any([s in o for o in out]):\n",
    "            out.append(s)\n",
    "    return out    \n",
    "    \n",
    "    \n",
    "# Tetst the function    \n",
    "longest_common_substring('egar_','cider_vinegar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate substrings**\n",
    "\n",
    "Find, for each ingredient a list of substrings that were found in common with other ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialise empty lists\n",
    "vect_substr = [] # List for vectorizer\n",
    "list_substr = [] # List for dictionary old vs new\n",
    "\n",
    "# For each ingredient in our bag of ingredients\n",
    "for ingr1 in X_train_cl.columns:\n",
    "    \n",
    "    # Initialise an empty list to store list of ingredients for one recipe (overwritten every time)\n",
    "    common_subs = []\n",
    "    \n",
    "    # For each ingredient in our bag of ingredients (we now have a pair (ingr1, ingr2))\n",
    "    for ingr2 in X_train_cl.columns:\n",
    "        \n",
    "        # Find the longest substring they have in common\n",
    "        match = longest_common_substring(ingr1, ingr2)\n",
    "        \n",
    "        # If there is a substring longer than 4 char, single word and isn't already included, append\n",
    "        if (match != \"\") and (match not in common_subs):\n",
    "            common_subs.append(match)\n",
    "\n",
    "    # Keep only unique substrings (not strings contained in others)\n",
    "    common_subs = uniqueString(common_subs)\n",
    "    \n",
    "    # From list of strings to a single string with spaces\n",
    "    vect_substr.append(' '.join([word for word in common_subs]))\n",
    "    list_substr.append(common_subs) # List of lists\n",
    "    \n",
    "# Create a dictionary with the ingredient and the list of substring found for it\n",
    "ingr_substr_dict = dict(zip(X_train_cl.columns, list_substr))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a new bag of words object with ingredients vs substrings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abura', 'seasoning cent', 'achiote', 'achiote paste', 'achiote powder']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample input for vectorizer\n",
    "vect_substr[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abura</th>\n",
       "      <th>achiote</th>\n",
       "      <th>ackee</th>\n",
       "      <th>acle</th>\n",
       "      <th>acor</th>\n",
       "      <th>active</th>\n",
       "      <th>added</th>\n",
       "      <th>adobo</th>\n",
       "      <th>adzuki</th>\n",
       "      <th>agar</th>\n",
       "      <th>...</th>\n",
       "      <th>yoghurt</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yolk</th>\n",
       "      <th>yolks</th>\n",
       "      <th>yukon</th>\n",
       "      <th>yuzu</th>\n",
       "      <th>zest</th>\n",
       "      <th>zinfandel</th>\n",
       "      <th>ziti</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abura_age</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accent_seasoning</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>achiote</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>achiote_paste</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>achiote_powder</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1713 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  abura  achiote  ackee  acle  acor  active  added  adobo  \\\n",
       "abura_age             1        0      0     0     0       0      0      0   \n",
       "accent_seasoning      0        0      0     0     0       0      0      0   \n",
       "achiote               0        1      0     0     0       0      0      0   \n",
       "achiote_paste         0        1      0     0     0       0      0      0   \n",
       "achiote_powder        0        1      0     0     0       0      0      0   \n",
       "\n",
       "                  adzuki  agar    ...     yoghurt  yogurt  yolk  yolks  yukon  \\\n",
       "abura_age              0     0    ...           0       0     0      0      0   \n",
       "accent_seasoning       0     0    ...           0       0     0      0      0   \n",
       "achiote                0     0    ...           0       0     0      0      0   \n",
       "achiote_paste          0     0    ...           0       0     0      0      0   \n",
       "achiote_powder         0     0    ...           0       0     0      0      0   \n",
       "\n",
       "                  yuzu  zest  zinfandel  ziti  zucchini  \n",
       "abura_age            0     0          0     0         0  \n",
       "accent_seasoning     0     0          0     0         0  \n",
       "achiote              0     0          0     0         0  \n",
       "achiote_paste        0     0          0     0         0  \n",
       "achiote_powder       0     0          0     0         0  \n",
       "\n",
       "[5 rows x 1713 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise CountVectorizer object\n",
    "vect_substr_bog = CountVectorizer()\n",
    "\n",
    "# Transform list of ingredients to bag-of-ingredients format, for train and \n",
    "# test sets, and store in a pandas data frame\n",
    "substr_df = pd.DataFrame(vect_substr_bog.fit_transform(vect_substr).todense())\n",
    "\n",
    "# Add column names, using keys from vectorizer dictionary\n",
    "substr_df.columns = sorted(vect_substr_bog.vocabulary_, \n",
    "                           key=vect_substr_bog.vocabulary_.get)\n",
    "\n",
    "# Add recipe id\n",
    "substr_df.index = X_train_cl.columns\n",
    "\n",
    "# Display first few rows of the generated dataframe\n",
    "substr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute popularity of substrings**\n",
    "\n",
    "To determine which part of the ingredient name to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq_ingr</th>\n",
       "      <th>freq_names</th>\n",
       "      <th>freq_recipes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abura</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>achiote</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ackee</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acle</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acor</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         freq_ingr  freq_names  freq_recipes\n",
       "abura            1           1             4\n",
       "achiote          3           3            23\n",
       "ackee            1           1             9\n",
       "acle             1           4            31\n",
       "acor             1           2            28"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute popularity of the substring among both ingredients and recipes, store in a dataframe\n",
    "substr_freq_names  = substr_df.sum(axis=0) # Count frequency of this substring in names\n",
    "substr_freq_ingr   = []                    # Count frequency of this substring in ingredients\n",
    "substr_freq_recipe = []                    # Count frequency of this substring in recipes\n",
    "\n",
    "for substr in substr_df.columns:\n",
    "    substr_freq_ingr.append(sum([substr in ingr for ingr in X_train_cl.columns]))\n",
    "    \n",
    "for substr in substr_df.columns:\n",
    "    substr_freq_recipe.append(sum([substr in recipe for recipe in train_ingr]))\n",
    "\n",
    "# Store in a dataframe\n",
    "subs_freq_df = pd.DataFrame(np.column_stack([substr_freq_names, substr_freq_ingr, substr_freq_recipe]), \n",
    "                               columns=['freq_ingr', 'freq_names', 'freq_recipes'])\n",
    "subs_freq_df.index = substr_freq_names.index\n",
    "\n",
    "# Display first rows\n",
    "subs_freq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array on which to modify the ingredient names\n",
    "new_columns = np.array(X_train_cl.columns)\n",
    "\n",
    "for elem_idx, elem in enumerate(X_train_cl.columns):\n",
    "    \n",
    "    # Old list of substrings\n",
    "    previous_list = np.array(ingr_substr_dict[elem])\n",
    "    \n",
    "    # Get 3 frequencies for all substrings in the ingredient\n",
    "    counts = subs_freq_df.loc[ingr_substr_dict[elem]]\n",
    "    \n",
    "    # Store each frequency separately, but keeping substrings together\n",
    "    ingr_count   = counts['freq_ingr'].values\n",
    "    name_count   = counts['freq_names'].values\n",
    "    recipe_count = counts['freq_recipes'].values\n",
    "    \n",
    "    # indeces of substrings that are popular enough\n",
    "    many_substr = np.logical_or(ingr_count + name_count > 50, recipe_count > 1000)\n",
    "    \n",
    "    # Keep only these substrings\n",
    "    new_list = list(previous_list[many_substr])\n",
    "    \n",
    "    # Join them in a single word to get a new ingredient name\n",
    "    new_list.sort(key=len, reverse=True)\n",
    "    if new_list != []: \n",
    "        new_columns[elem_idx] = '_'.join([word for word in new_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingredients combined: 1494\n",
      "Unique ingredients now: 2162\n"
     ]
    }
   ],
   "source": [
    "print(\"Ingredients combined:\",X_train_cl.shape[1] - len(np.unique(new_columns)))\n",
    "print(\"Unique ingredients now:\", len(np.unique(new_columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine columns in dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace old columns\n",
    "old_replaced = [] # List to store columns to be dropped\n",
    "\n",
    "for old, new in zip(old_columns, new_columns):\n",
    "    if new not in X_train_cl_copy.columns:\n",
    "        # Create column new name\n",
    "        X_train_cl_copy[new] = X_train_cl_copy[old] \n",
    "        old_replaced.append(old)\n",
    "    elif new != old:\n",
    "        # Combine old and new column in one\n",
    "        X_train_cl_copy[new] = np.minimum(1, np.array(X_train_cl_copy[old] + X_train_cl_copy[new]))\n",
    "        old_replaced.append(old)\n",
    "\n",
    "# Drop old columns        \n",
    "X_train_cl_copy.drop(columns = old_replaced, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove infrequent ingredients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* ingredients removed for being numeric or appearing <= 50 times 157\n"
     ]
    }
   ],
   "source": [
    "# Compute ingredient frequencies\n",
    "ingr_count = X_train_cl_copy.sum(axis=0)\n",
    "\n",
    "# Ingredients that appear three times or less\n",
    "not_many_ingr = list(ingr_count <= 200)                        \n",
    "\n",
    "# Sum number of ingredients that appear 3 times or less.\n",
    "print('* ingredients removed for being numeric or appearing <= 50 times',sum(not_many_ingr))\n",
    "\n",
    "# Drop infrequent ingredients\n",
    "X_train_cl_copy.drop(X_train_cl_copy.columns[not_many_ingr], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display remanining ingredients\n",
    "remaining_ingr = list(X_train_cl_copy.columns)\n",
    "remaining_ingr.sort()\n",
    "remaining_ingr\n",
    "\n",
    "# Manually remove irrelevant inredients\n",
    "irrelevant = ['water', 'salt', 'white', 'chopped_fresh', 'chopped', 'dried', 'fresh','frozen',\n",
    "             'green', 'ground','halfhalf','large','leaves','paste','powder','sauce','sliced','star',\n",
    "             'yellow']\n",
    "\n",
    "X_train_cl_copy.drop(columns = irrelevant, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove recipes with too many or too few ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipes with 2 ingredients or less: 894\n"
     ]
    }
   ],
   "source": [
    "# Count ingredients per recipe.\n",
    "recipe_count = X_train_cl_copy.sum(axis = 1)\n",
    "print('Recipes with 2 ingredients or less:', sum(recipe_count <= 2))\n",
    "\n",
    "not_too_few_idx = list(recipe_count > 2)\n",
    "not_too_many_idx = list(recipe_count < 30)\n",
    "\n",
    "# Remove recipes with <3 or >30 ingredients.\n",
    "X_train_cl_copy = X_train_cl_copy.loc[[a and b for a, b in zip(not_too_few_idx, not_too_many_idx)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:\n",
      " *  37704 recipes\n",
      " *  311 ingredients\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data size:\\n *  {} recipes\\n *  {} ingredients\".format(X_train_cl_copy.shape[0], \n",
    "                                                                       X_train_cl_copy.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "### Other methods tried to combine ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following [this](https://pdfs.semanticscholar.org/3f63/269aa7910774e9386b1ffb340a9e8638c02d.pdf) paper: <br>\n",
    "\"From the list of ingredients, a dictionary of the 355 most common ingredients occurring in at least 120 recipes was hand curated, then each recipe’s ingredient list was filtered with these words so that ingredients such as ‘1/2 teaspoon ground cardamom’ were reduced to simple ingredient features such as ‘cardamom’. In the end, the ingredients for each recipe were represented in an R355 binary vector, where the element in index i is 1 if ingredient i is present in the recipe, and 0 if absent. Quantities of the ingredients used were not taken into account.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_common = 100 # Number of most common ingredients to keep.\n",
    "ingr_count.sort_values(ascending = False, inplace = True) # Sort the list with ingredients by count.\n",
    "common_ingredients = list(ingr_count[:n_common].index) # Save the most common ingredients.\n",
    "noncommon_ingredients = [i for i in X_train.columns if not i in common_ingredients] # Save the noncommon ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all common ingredients from longest string to shortest.\n",
    "for common_ingr in sorted(common_ingredients, key = len, reverse = False):\n",
    "    regex = re.compile('.*' + common_ingr + '.*')\n",
    "    \n",
    "    # Find the non-common ingredients matching this common ingredient.\n",
    "    ingr_to_group = list(filter(regex.search, noncommon_ingredients))\n",
    "    \n",
    "    if ingr_to_group != None:\n",
    "        \n",
    "        # Combine equivalent ingredients in the common ingredient's column.\n",
    "        X_train[common_ingr] = list(map(int, (X_train[ingr_to_group].sum(axis = 1) + X_train[common_ingr] >= 1)))\n",
    "    \n",
    "        # Drop the grouped non-common ingredients from the dataset.\n",
    "#         X_train.drop(columns = ingr_to_group, inplace = True)\n",
    "#         noncommon_ingredients = [i for i in X_train.columns if not i in common_ingredients]\n",
    "        \n",
    "X_train.drop(columns = noncommon_ingredients, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check new ingredient counts.\n",
    "ingr_count2 = X_train.drop(columns='cuisine').sum(axis=0)\n",
    "ingr_count2.sort_values(ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add back cuisine information and save preprocessed data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>active_dry_yeast</th>\n",
       "      <th>allpurpose_flour</th>\n",
       "      <th>asparagus</th>\n",
       "      <th>avocado</th>\n",
       "      <th>bacon</th>\n",
       "      <th>baguette</th>\n",
       "      <th>baking_soda</th>\n",
       "      <th>bananas</th>\n",
       "      <th>basil</th>\n",
       "      <th>beans</th>\n",
       "      <th>...</th>\n",
       "      <th>vegetable</th>\n",
       "      <th>potatoes_sweet</th>\n",
       "      <th>vegetable_cooking_spray</th>\n",
       "      <th>vinegar_white</th>\n",
       "      <th>onion_white</th>\n",
       "      <th>pepper_white</th>\n",
       "      <th>vinegar_white_wine</th>\n",
       "      <th>flour_wheat_whole</th>\n",
       "      <th>pepper_yellow_bell</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10259</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25693</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20130</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>filipino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13162</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jamaican</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       active_dry_yeast  allpurpose_flour  asparagus  avocado  bacon  \\\n",
       "10259                 0                 0          0        0      0   \n",
       "25693                 0                 0          0        0      0   \n",
       "20130                 0                 0          0        0      0   \n",
       "13162                 0                 0          0        0      0   \n",
       "6602                  0                 0          0        0      0   \n",
       "\n",
       "       baguette  baking_soda  bananas  basil  beans     ...       vegetable  \\\n",
       "10259         0            0        0      0      1     ...               0   \n",
       "25693         0            0        0      0      0     ...               1   \n",
       "20130         0            0        0      0      0     ...               0   \n",
       "13162         0            0        0      0      0     ...               0   \n",
       "6602          0            0        0      0      0     ...               0   \n",
       "\n",
       "       potatoes_sweet  vegetable_cooking_spray  vinegar_white  onion_white  \\\n",
       "10259               0                        0              0            0   \n",
       "25693               0                        0              0            0   \n",
       "20130               0                        0              0            0   \n",
       "13162               0                        0              0            0   \n",
       "6602                0                        0              0            0   \n",
       "\n",
       "       pepper_white  vinegar_white_wine  flour_wheat_whole  \\\n",
       "10259             0                   0                  0   \n",
       "25693             0                   0                  0   \n",
       "20130             0                   0                  0   \n",
       "13162             0                   0                  0   \n",
       "6602              0                   0                  0   \n",
       "\n",
       "       pepper_yellow_bell      cuisine  \n",
       "10259                   0        greek  \n",
       "25693                   0  southern_us  \n",
       "20130                   0     filipino  \n",
       "13162                   0       indian  \n",
       "6602                    0     jamaican  \n",
       "\n",
       "[5 rows x 312 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cl_copy['cuisine'] = [cuisine_dict[key] for key in X_train_cl_copy.index]\n",
    "X_train_cl_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cl_copy.to_csv('train_dataset.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
